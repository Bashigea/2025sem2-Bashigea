---
title: "Day 7 Homework, DST 490"
author: "Armand Bashige"
date: "2026-02-08"
format:
  html:
    embed-resources: true
editor: source
---

```{r}
#| echo: false
#| message: false

library(tidyverse)

# Load in datasets you will need when rendering the file.

# Unemployment and education data from the USDA. See day07_README.md for data sources

# Name of the uemployment file
unemployment_file <- "Unemployment.xlsx"

unemployment <- readxl::read_excel(unemployment_file,
                                   skip = 4,
                                   sheet = 'UnemploymentMedianIncome')

# Name of the file to read in:
education_file <- "Education.xlsx"


education <- readxl::read_excel(education_file ,
                                skip = 3,
                                sheet = 'Education 1970 to 2022')

```

Link to google doc for instructions: [LINK](https://docs.google.com/document/d/1KfKKnusjZ4H2zL1x9caBJSl-QA5b4rHosojLG1ITQM0/edit?usp=sharing)



<div style="background-color: #f0f8ff; border-left: 5px solid #007acc; padding: 10px;">
## (20 points) Code of Ethics
I'm interested in understanding your process for completing all the questions in this assignment. Please tell me about the tools and resources—including any use of AI—that helped you with your work. Please remember to follow the outlined [Code of Ethics](https://docs.google.com/document/d/1lMvzPTGUAaMnH0KPibShQ1ualuo8uqICCexkh8zmsW8/edit?usp=sharing).  Because our understanding of how to work with AI tools is emerging, please err on the side of including too much detail rather than too little.


The code I wrote is based on the Day 7 class activity code provided by the professor. I used it as a reference and guide to fix my errors. I did not copy any outside code from the internet or use any unauthorized resources.

</div>



## (10 points) 1. Reading Advanced R
Read [Chapter 9 of Advanced R by Wickham](https://adv-r.hadley.nz/functionals.html). What did you learn about functionals and what questions do you still have about them?

  I learned that a functional is basically a function that takes another function as its input and gives back a vector as output. The cool thing about functionals is that they are a cleaner way to do repetitive tasks instead of writing for loops. For example, map() goes through each element in a list and applies a function to it, which is much easier to read than writing a whole loop. There are also different versions of map() depending on what type of output you want, like map_dbl() for numbers or map_chr() for characters. 
  I also learned about map2() which lets you work with two lists at the same time, and walk() which is useful when you just want to do something like save a file without needing a return value. The reduce() function was also interesting because it takes a whole list and keeps applying a function until you get one single result.
  
  One question I still have is about when to use pmap() versus map2() since they seem to do similar things. I also am not totally sure when I would choose modify() over regular map() in a real project.

## (20 points) 2. Functional programming for Hennepin County
Discuss with your Hennepin County project group: how do you foresee yourself using nest, map, and functions on the dataset? Assign someone to try it out to see if they can get some progress!


  After thinking about our Hennepin County project, I can see a few ways that nest(), map(), and functions would be useful on our dataset. For example, we could use nest() to group the data by neighborhood or district, and then use map() to apply the same analysis or visualization to each group without repeating code. This would be really helpful if we wanted to compare trends across different areas of Hennepin County without writing separate code for each one. We could also write a custom function that cleans or summarizes a specific variable, and then use map() to apply it across all the nested groups at once, making our workflow much more efficient and organized.
  
  As for assigning someone to try it out, I was not able to do that since I am submitting this assignment late and did not have the chance to coordinate with my group in time. However, based on what we have learned in class, I think this approach would be a good starting point for the group to explore.


## (20 points) 3. Average unemployment workflow

In class we computed the average unemployment for each FIPS code. Instead, start with the `unemployment` dataset to write a workflow that computes the average unemployment for each state.

```{r}
# Define the compute_unemployment function first
compute_unemployment <- function(input_data, year_span) {
  
  avg_val <- input_data |>
    select(starts_with("Unemployment_rate")) |>
    pivot_longer(cols = everything()) |>
    separate_wider_position(name, c(name = 18, Year = 4)) |>
    mutate(Year = as.numeric(Year)) |>
    filter(Year %in% year_span) |>
    summarize(avg_unemploy = mean(value, na.rm = TRUE)) |>
    pull(avg_unemploy)
  
  return(avg_val)
}

# Filter out the national and state-level summary rows first
# Then create a nested list organized by State
nested_unemployment <- unemployment |>
  filter(!is.na(Rural_Urban_Continuum_Code_2013)) |>
  group_by(State) |>
  nest()

# Using map_dbl to compute the average unemployment for each state
unemployment_span <- nested_unemployment |>
  mutate(unemployment_pct_2008_2012 = map_dbl(.x = data,
                                     .f = ~compute_unemployment(.x, 2018:2022))) |>
  select(-data)

glimpse(unemployment_span)
```

## (15 points) 4. Recreate this plot
From `joined_dataset`, recreate this exact plot shown here in the [assignment instructions](https://docs.google.com/document/d/1KfKKnusjZ4H2zL1x9caBJSl-QA5b4rHosojLG1ITQM0/edit?usp=sharing).
 


```{r}
# First create the joined_dataset like the professor did in class
education_small <- education |>
  select(`FIPS Code`, State, ends_with("2008-12")) |>
  select(`FIPS Code`, State, starts_with("Percent"))

joined_dataset <- unemployment_span |>
  inner_join(education_small, by = "State")

joined_dataset |>
  pivot_longer(cols = starts_with("Percent"),
               names_to = "Educational_factor",
               values_to = "Educational_factor_value") |>
  ggplot(aes(x = Educational_factor_value,
             y = unemployment_pct_2008_2012)) +
  geom_point() +
  geom_smooth(method = 'lm') +
  facet_wrap(~ Educational_factor) +
  labs(x = "Educational factor",
       y = "Average Unemployment Rate (%, 2018-2022)")
```

## (40 points) 5. New visualization for state unemployment data
Using the `joined_dataset` (`unemployment_span` and `education_small` data sets) to answer the following questions:

  a. First, **ON YOUR OWN**, using the joined_dataset, write a function called `state_plot` that has as its output, the average unemployment rate with an educational factor for a given state.  A sample plot is shown in the [assignment instructions](https://docs.google.com/document/d/1KfKKnusjZ4H2zL1x9caBJSl-QA5b4rHosojLG1ITQM0/edit?usp=sharing). Your plot needs to include the state as a title.

For this first step, you are not allowed to utilize any additional websites or AI. I want to see what you can do on your own first - so make a good-faith effort to resolve any errors in your work. Note that the code chunk evaluation option is set to false (`#| eval: false`) so that the quarto file won't throw an error when rendering.^[If you are successful in making a visualization, then change the option from `false` to `true`.]

```{r}
#| eval: false
#| message: false

state_plot <- function(state_name) {
  
  joined_dataset |>
    filter(State == state_name) |>
    ggplot(aes(x = `Percent of adults with less than a high school diploma, 2008-12`,
               y = unemployment_pct_2008_2012)) +
    geom_point() +
    geom_smooth(method = 'lm') +
    labs(title = state_name,
         x = "Percent of adults with less than a high school diploma, 2008-12",
         y = "Average Unemployment Rate (%, 2018-2022)")
}

state_plot(state_name = "MN")

```

  b. Reflect on your work.  What were the errors that you received? What skills and knowledge gaps can you identify?

  I was getting simple errors which were syntax errors and I resolved them by myself. However, when I first tried to write the state_plot function, the code actually ran without any error messages, which made me think it worked. But looking at the output plot, all the points were flat on the same y-value around 4.12, which means something was wrong. The issue was not an error in the code itself, but rather a problem with how the data was set up. Because in question 3, I grouped by State instead of FIPS_Code, the unemployment average was calculated once per state, meaning every county in Minnesota got the same unemployment number. This made the plot look flat and meaningless.
  
  One skill gap I can identify is understanding how grouping affects the data downstream. I did not think about how changing group_by(FIPS_Code) to group_by(State) in Q3 would break the plot in Q5. Another gap is being able to look at a plot and immediately recognize when something looks wrong with the data, not just the code.

  c. If you have errors in your visualization, make corrections to resolve them:

```{r}
#| message: false

nested_unemployment <- unemployment |>
  filter(!is.na(Rural_Urban_Continuum_Code_2013)) |>
  group_by(FIPS_Code) |>
  nest()

unemployment_span <- nested_unemployment |>
  mutate(unemployment_pct_2008_2012 = map_dbl(.x = data,
                                     .f = ~compute_unemployment(.x, 2018:2022))) |>
  select(-data)

joined_dataset <- unemployment_span |>
  inner_join(education_small, by = c("FIPS_Code" = "FIPS Code"))

state_plot(state_name = "MN")

```

  d. As you resolved the errors, what were your sources? Be sure to complete the Code of Ethics.
  
  To resolve the errors, I went back to the Day 7 class activity code and worked through it carefully. The class code provided the base structure I needed to fix the grouping issue and get the function working correctly.
    
  e. Now I want you to modify your visualization with a different plot geom. The website [from data to viz](https://www.data-to-viz.com/) is useful for inspiration.  You may need to load / install additional libraries as needed.
    
```{r}
#| message: false
state_plot_violin <- function(state_name) {
  
  joined_dataset |>
    filter(State == state_name) |>
    pivot_longer(cols = starts_with("Percent"),
                 names_to = "Educational_factor",
                 values_to = "Educational_factor_value") |>
    ggplot(aes(x = Educational_factor,
               y = unemployment_pct_2008_2012)) +
    geom_violin(fill = "lightblue") +
    labs(title = state_name,
         x = "Educational Factor",
         y = "Average Unemployment Rate (%, 2018-2022)") +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
}

state_plot_violin(state_name = "MN")

```
   
  f. What trends do you see in the visualization? What is your explanation for these trends? 

  From the violin plot for Minnesota, one trend I noticed is that the distribution of average unemployment rates looks fairly similar across the different education groups. However, counties with a higher percentage of adults with less than a high school diploma seem to have a slightly wider distribution, meaning the unemployment rates in those counties vary more. The violin shapes for higher education groups like bachelor's degree or higher appear to be more narrow and concentrated at lower unemployment values, suggesting those counties tend to have more consistent and lower unemployment rates.
  
  This could be explained by the fact that areas with more college educated people tend to have more stable job markets, while areas with lower education levels may experience more ups and downs in employment depending on the type of work available in that area.


